{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbzj7p+OvnpO0QHOKfb+cY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilavantakula/special-octo-computing-machine/blob/main/MLP_NPPE_2_MODEL_BUILDING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR0dJp_ccPHH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "df=pd.read_csv('/content/T124OPPE2_ModelBuilding_V1.csv')\n",
        "x,y=df.iloc[:,:-1],df.iloc[:,-1]\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions (Q2-Q3)\n",
        "Instantiate a perceptron classifier that with following parameters:\n",
        "\n",
        "\trandom_state = 1729\n",
        "\tlearning rate = 1\n",
        "\tTrain for appropriate number of iterations\n",
        "\tDo not shuffle the dataset for each iteration.\n",
        "\tInclude the intercept (bias) term.\n",
        "\tUse 10% of the data for validation fraction.\n",
        "\tDo not apply regularization.\n",
        "\tSet warm start to true.\n",
        "\n",
        "Hint: one iteration of training indicates going over each sample exactly once.\n",
        "\n",
        "Train the classifier on the training data.\n",
        "\n",
        "\n",
        "Train the perceptron classifier for 5 iterations. What is value of bias (intercept) after 5th iteration?"
      ],
      "metadata": {
        "id": "4ktEpXjhiWnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import Perceptron\n",
        "perceptron=Perceptron(\n",
        "    random_state = 1729,\n",
        "    eta0 = 1,\n",
        "    shuffle =False,\n",
        "    fit_intercept=True,\n",
        "    validation_fraction=0.1,\n",
        "    penalty=None,\n",
        "    warm_start=True\n",
        ")\n",
        "for i in range(5):\n",
        "  perceptron.partial_fit(x_train,y_train,classes=np.unique(y_train))\n",
        "perceptron.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmvrefg0dHFR",
        "outputId": "4a4523d9-08a8-4690-85b6-5d1d9b297f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In continuation of the previous question, compute precision accurate upto 2 decimal places on training data for positive class (i.e. class value 1), after 5 iterations.\n",
        "\n",
        "[Hint: Use estimator trained from the previous question]\n"
      ],
      "metadata": {
        "id": "9s2TjUR7jF7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "y_pred=perceptron.predict(x_train)\n",
        "precision_score(y_train,y_pred,pos_label=1,zero_division=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY_rZPHceEg3",
        "outputId": "4127f8ca-3115-42f8-cb72-ec3c86ff629f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train (on training data only) logistic regression using SGDClassifier. Use the following parameters:\n",
        "\n",
        "\tChoose appropriate loss value to obtain logistic regression\n",
        "\tpenalty='l2',\n",
        "\teta0=0.001,\n",
        "\talpha=0,\n",
        "\tlearning_rate='constant'\n",
        "\trandom_state=1729.\n",
        "\twarm_start = True\n",
        "\n",
        "Train the classifier for 5 iterations and note the value of the loss in each iteration. What will be the loss value after second iteration? Answer upto three decimal places.\n",
        "\n",
        "Note: Set the remaining parameters, if any, accordingly to be able to get the loss value after second iteration. Also note that the classifier has to be trained for 5 iterations."
      ],
      "metadata": {
        "id": "eQ-EPf39jJ4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "sgd=SGDClassifier(\n",
        "    loss='log_loss',\n",
        "    penalty='l2',\n",
        "    eta0=0.001,\n",
        "    alpha=0,\n",
        "    learning_rate='constant',\n",
        "    random_state=1729,\n",
        "    warm_start=True,\n",
        ")\n",
        "loss_value=[]\n",
        "for i in range(5):\n",
        "  sgd.partial_fit(x_train,y_train,classes=np.unique(y_train))\n",
        "  y_pred_proba = sgd.predict_proba(x_train)\n",
        "  loss = log_loss(y_train, y_pred_proba)\n",
        "  loss_value.append(loss)\n",
        "loss_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyTLR0wueyIW",
        "outputId": "35dfdbba-6d60-48a0-ba54-0d50c6857830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2529904609012919,\n",
              " 0.20828682141739835,\n",
              " 0.19406901833322654,\n",
              " 0.18699850891012404,\n",
              " 0.18255077295024025]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1 point\n",
        "Use GridSearchCV with SGDClassifier. Following are the classifier's parameters:\n",
        "\n",
        "\tloss = 'log_loss'\n",
        "\tlearning_rate = 'constant'\n",
        "\trandom_state = 1729\n",
        "\n",
        "Following are parameters to examine:\n",
        "\n",
        "\talpha = [0.0001, 0.0005, 0.001, 0.005]\n",
        "\teta0 = [0.01, 0.05, 0.1, 0.5]\n",
        "\n",
        "What are the best values of alpha and eta0 respectively?"
      ],
      "metadata": {
        "id": "LqcPNDfzjOOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid={\n",
        "    'alpha':[0.0001, 0.0005, 0.001, 0.005],\n",
        "    'eta0' : [0.01, 0.05, 0.1, 0.5]\n",
        "}\n",
        "classifer=SGDClassifier(\n",
        "    loss = 'log_loss',\n",
        "    learning_rate = 'constant',\n",
        "    random_state = 1729\n",
        ")\n",
        "grid_search=GridSearchCV(\n",
        "    estimator=classifer,\n",
        "    param_grid=param_grid,\n",
        ")\n",
        "grid_search.fit(x_train,y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIYVM-tZgcMH",
        "outputId": "9d619d22-eccc-4940-e34a-f9b9ac27f76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.0001, 'eta0': 0.01}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new estimator using SGDClassifier that uses the best parameters obtained in Gridsearch earlier ((learning rate to be constant, random_state to be '1729' and use appropriate loss for logistic regression)) and set the weight of class 0 to be 0.1 and the weight of class 1 to be 2. How many samples of class 1 from the test set are correctly predicted by this estimator?"
      ],
      "metadata": {
        "id": "U4n7fPNGjSaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "sgd_classifier=SGDClassifier(\n",
        "    loss='log_loss',\n",
        "    learning_rate='constant',\n",
        "    random_state=1729,\n",
        "    alpha=0.0001,\n",
        "    eta0=0.01,\n",
        "    class_weight={0:0.1,1:2}\n",
        ")\n",
        "sgd_classifier.fit(x_train,y_train)\n",
        "y_pred=sgd_classifier.predict(x_test)\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF3tfouEhC_G",
        "outputId": "437e9718-f740-47b4-e824-03d707b4139d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[843, 299],\n",
              "       [ 11,  47]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit an SVM classifier with following parameters:\n",
        "\n",
        "\tkernel='rbf'\n",
        "\tdecision_function_shape='ovr'\n",
        "\trandom_state=1729\n",
        "\tC=1\n",
        "\n",
        "Train the model on training data, and print the confusion matrix on test data."
      ],
      "metadata": {
        "id": "6ivFsZkCjXRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm=SVC(\n",
        "    kernel='rbf',\n",
        "\t  decision_function_shape='ovr',\n",
        "\t  random_state=1729,\n",
        "\t  C=1\n",
        ")\n",
        "svm.fit(x_train,y_train)\n",
        "y_pred=svm.predict(x_test)\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZavV0tnhxQu",
        "outputId": "ee310242-e95f-4986-c6ab-e4d73d0b2816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1142,    0],\n",
              "       [  58,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Decision Tree Classifier with the following properties:\n",
        "\n",
        "\tcriterion = 'entropy',\n",
        "\tsplitter = 'random',\n",
        "\tmin_samples_split = 4,\n",
        "\tmin_impurity_decrease = 0.0001,\n",
        "\trandom_state = 1729\n",
        "\n",
        "What is the resultant depth of the tree?\n",
        "How many nodes are there in the tree?"
      ],
      "metadata": {
        "id": "HATYxGJojbTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree=DecisionTreeClassifier(\n",
        "    criterion = 'entropy',\n",
        "    splitter = 'random',\n",
        "    min_samples_split = 4,\n",
        "    min_impurity_decrease = 0.0001,\n",
        "    random_state = 1729\n",
        ")\n",
        "decision_tree.fit(x_train,y_train)\n",
        "print(decision_tree.get_depth(),decision_tree.tree_.node_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwM9sFGNiADO",
        "outputId": "e0d5d266-3631-4373-d581-cfea016ec328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the value of entropy at the left child of root?"
      ],
      "metadata": {
        "id": "KUKkPIm2jnfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree.tree_.impurity[decision_tree.tree_.children_left[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtMehxQxizMm",
        "outputId": "355f4f06-893b-4780-91f0-88519de2422b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.024564134553940277"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of DecisionTreeClassifier, KNeighborsClassifier and LogisticRegression, which one performs the best when used as base estimator in BaggingClassifier on the test data in terms of accuracy score when 20 base estimators are used ?\n",
        "(Use random state 1729 for BaggingClassifier, DecisionTreeClassifier and LogisticRegression)\n",
        "\n",
        "The metric for best performance will be the lowest 'absolute' difference in the train and test score.\n",
        "\n",
        "DecisionTreeClassifie\n",
        "\n",
        "KNeighborsClassifier\n",
        "\n",
        "LogisticRegression"
      ],
      "metadata": {
        "id": "Tc8p7ZrCjo7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "dtc=DecisionTreeClassifier(random_state=1729)\n",
        "knc=KNeighborsClassifier()\n",
        "lr=LogisticRegression(random_state=1729)\n",
        "bagging_dtc=BaggingClassifier(\n",
        "    base_estimator=dtc,\n",
        "    n_estimators=20,\n",
        "    random_state=1729)\n",
        "bagging_knc=BaggingClassifier(\n",
        "    base_estimator=knc,\n",
        "    n_estimators=20,\n",
        "    random_state=1729)\n",
        "bagging_lr=BaggingClassifier(\n",
        "    base_estimator=lr,\n",
        "    n_estimators=20,\n",
        "    random_state=1729)\n",
        "bagging_dtc.fit(x_train,y_train)\n",
        "bagging_knc.fit(x_train,y_train)\n",
        "bagging_lr.fit(x_train,y_train)\n",
        "y_pred_dtc=bagging_dtc.predict(x_test)\n",
        "y_pred_knc=bagging_knc.predict(x_test)\n",
        "y_pred_lr=bagging_lr.predict(x_test)\n",
        "print(accuracy_score(y_test,y_pred_dtc))\n",
        "print(accuracy_score(y_test,y_pred_knc))\n",
        "print(accuracy_score(y_test,y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3Gjp_J6j-SL",
        "outputId": "3c7736ac-a8b5-4370-f164-ca5a9ff51223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9441666666666667\n",
            "0.9508333333333333\n",
            "0.9516666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the above three individual classifiers (with same settings) are used in VotingClassifier, how much absolute difference do we obtain in train and test scores? Enter your answer correct upto 4 decimal places."
      ],
      "metadata": {
        "id": "D4noKRFTjuWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=1729)\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "lr_classifier = LogisticRegression(random_state=1729)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('dt', dt_classifier),\n",
        "        ('knn', knn_classifier),\n",
        "        ('lr', lr_classifier)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_clf.fit(x_train, y_train)\n",
        "y_train_pred = voting_clf.predict(x_train)\n",
        "y_test_pred = voting_clf.predict(x_test)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "absolute_difference = abs(train_accuracy - test_accuracy)\n",
        "print(f\"Absolute difference between train and test scores: {absolute_difference:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6b2TLK7k7Z7",
        "outputId": "30df56f2-a5c5-4101-c3fd-ae6283bbcf6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute difference between train and test scores: 0.0043\n"
          ]
        }
      ]
    }
  ]
}